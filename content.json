{"meta":{"title":"Feng kai","subtitle":null,"description":null,"author":"Feng Kai","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"StyleGAN","slug":"StyleGAN","date":"2019-09-28T08:43:17.000Z","updated":"2019-09-28T08:43:45.758Z","comments":true,"path":"2019/09/28/StyleGAN/","link":"","permalink":"http://yoursite.com/2019/09/28/StyleGAN/","excerpt":"","text":"源代码： https://github.com/NVlabs/stylegan Encoder参考：https://github.com/eyaler/stylegan-encoder 1. StyleGAN网络####1.1 基本介绍该网络由NVIDIA提出于2018.11，同时发表了文章A Style-Based Generator Architecture for Generative Adversarial Networks，主要改进了ProGAN的生成器部分.映射网络的目标是将输入向量编码为中间，不同元素控制视觉特征。映射网络由8个全连接层组成，它的输出 ⱳ(512*18),输入为(512×1). ####1.2 特征组成 ⱳ(512*18)分别代表着18个维度不同的人脸特征，14一般代表人脸的姿态、发型、面部形状等；58一般代表更为细致的特征；9~10主要是颜色部分；具体不一部分影响的细节可以参考NVIDIA给出的视频介绍 2. StyleGAN-Encoder####2.1 使用Encoder的原因StyleGAN网络只能接受随机向量(Lantent z)进行人脸的生成，为了使StyleGAN可以使用我们现实中拍摄的图像，所以需要StyleGAN Encoder将图像编码为StyleGAN可以识别的编码。Encoder部分本质上为Resnet网络，整体思路如下：利用generator这一特性给Resnet提供数据源，标签为之前输入Generator的随机向量。完成训练之后，该Resnet可以提取真实照片特征，也就是对真实数据映射到StyleGAN的编码器。但是，为了使得每次编码器都能输入StyleGAN后得到同一人像的输出，在实际生成是还需要添加几次的训练微调过程，在这里会花费相当多的时间。 3. StyleGAN 实例测试####3.1随机人像生成该网络可对人像进行随机生成，在实际功能验证中随机生成了500个人脸。在生成的全过程，我们只需要对该网络提供随机数即可。具体生成情况见下图生成500个人脸花费时间没有具体度量，大概在几分钟左右（GPU 1060 6G，&lt;5mins）。图像数据结果较佳，在对图像进行细看时，发现偶有图像成像效果一般，例如严重的兔唇，或者脸部空洞。生成的图像尺寸皆为1024*1024。后期再生成：StyleGAN网络的人脸生成完全依赖于外部随机向量的输入，也就是说只要输入同样的随机向量于StyleGAN网络中，生成的人脸图像完全一致。计算机随机数的生成依赖随机种子(Seed)的选取，选择同样的随机种子便代表同一人脸的再次生成。 ####3.2人脸A与B的融合下面展示两张同学的照片，从采集得到的原图到融合的全部过程： 原图：可见两张图像的尺寸并不一样，首先便需要将两张图像的人脸部分检测出来，之后对图像进行剪裁为StyleGAN适用的1024*1024的尺寸 人脸剪裁：使用基于python的Dlib库对人脸进行检测，该库可以检测人脸68或者更多的特征点。Dlib完全开源，并提供训练好的模型予以使用。一般来说Dlib对人脸的检测效果要优于OpenCV。人脸检测剪裁后的尺寸为（1024*1024） StyleGAN网络图像生成：StyleGAN只能依赖随机向量生成人脸图像，所以此生成过程不可控。依靠StyleGAN无法生成我们想让网络进行融合演进的图像，原因是我们无法给网络提供上述图像对应的且被StyleGAN识别的特征向量。解决方案为对StyleGAN添加RensNet对我们的图像进行编码，具体过程见理论部分。生成结果见下图： 需要注意的是，上图虽然和我们提供的照片比较相似，但是他完全由StyleGAN网络生成，我们只给他提供了一个ResNet网络输出的多维向量。网络依照特征向量（encode）生成图像，生成的人物与原图人物接近。仔细分辨发现多余的头发丝会被处理，皮肤会更为平滑美白，衣物基本不变，背景会被模糊。 将上述二人进行图像融合（上方的人脸称为A，左下方的人脸称为B，融合人脸称为C）：可见，融合的结果基本采用A人脸的年龄、性别、姿态、发型、衣物形状，采用B人物的肤色、发色、衣物颜色、眼睛形状、背景样式等信息。 ####3.3人脸的年龄与性别的变化提取人物年龄和性别的变化特征矩阵，使用上述矩阵的影响可对人物的年龄、性别、笑容等多维度进行自定义变换。具体细节可以参考Encoder代码 ###参考文献 [1]. Springenberg, J.T., et al., Striving for Simplicity: The All Convolutional Net. 2014. [2]. Karras, T., et al., Progressive Growing of GANs for Improved Quality, Stability, and Variation. 2017. [3]. Goodfellow, I.J., Generative Adversarial Nets. [4]. Karras, T., S. Laine and T. Aila, A Style-Based Generator Architecture for Generative Adversarial Networks. 2018. [5]. http://www.gwylab.com/note-gans.html","categories":[],"tags":[]},{"title":"First--Blog","slug":"first-blog","date":"2019-09-26T07:10:19.000Z","updated":"2019-09-26T07:36:41.489Z","comments":true,"path":"2019/09/26/first-blog/","link":"","permalink":"http://yoursite.com/2019/09/26/first-blog/","excerpt":"后续会思索一下具体分享内容大概会是如下的内容： 1.视频目标检测2.视频检索3.视频语义描述 分享一些论文阅读的心得和编程遇到的问题～","text":"后续会思索一下具体分享内容大概会是如下的内容： 1.视频目标检测2.视频检索3.视频语义描述 分享一些论文阅读的心得和编程遇到的问题～ 其他内容：1.生活杂记","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-09-26T03:06:25.468Z","updated":"2019-09-26T03:06:25.468Z","comments":true,"path":"2019/09/26/hello-world/","link":"","permalink":"http://yoursite.com/2019/09/26/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}